\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand*\HyPL@Entry[1]{}
\HyPL@Entry{0<</S/D>>}
\selectlanguage *{english}
\@writefile{toc}{\selectlanguage *{english}}
\@writefile{lof}{\selectlanguage *{english}}
\@writefile{lot}{\selectlanguage *{english}}
\HyPL@Entry{2<</S/r>>}
\HyPL@Entry{4<</S/D>>}
\newlabel{docs/index::doc}{{}{1}{}{section*.2}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{3}{chapter.1}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{docs/intro:introduction}{{1}{3}{Introduction}{chapter.1}{}}
\newlabel{docs/intro::doc}{{1}{3}{Introduction}{chapter.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Purpose of these lectures}{3}{section.1.1}\protected@file@percent }
\newlabel{docs/intro:purpose-of-these-lectures}{{1.1}{3}{Purpose of these lectures}{section.1.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Biological inspiration}{3}{section.1.2}\protected@file@percent }
\newlabel{docs/intro:biological-inspiration}{{1.2}{3}{Biological inspiration}{section.1.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.1}{\ignorespaces Biological neuron (from \sphinxhref {https://training.seer.cancer.gov/anatomy/nervous/tissue.html}{here}).}}{4}{figure.1.1}\protected@file@percent }
\newlabel{docs/intro:neuron-fig}{{1.1}{4}{Biological neuron (from \sphinxhref {https://training.seer.cancer.gov/anatomy/nervous/tissue.html}{here})}{figure.1.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.2}{\ignorespaces A small brain sample with axons clearly visible (from \sphinxhref {https://www.dailykos.com/stories/2021/6/12/2034998/-Top-Comments-Most-Intensive-Study-of-Brain-Neuron-Connections-Reveals-Never-Before-Seen-Structures}{here})}}{5}{figure.1.2}\protected@file@percent }
\newlabel{docs/intro:sample-fig}{{1.2}{5}{A small brain sample with axons clearly visible (from \sphinxhref {https://www.dailykos.com/stories/2021/6/12/2034998/-Top-Comments-Most-Intensive-Study-of-Brain-Neuron-Connections-Reveals-Never-Before-Seen-Structures}{here})}{figure.1.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.3}{\ignorespaces White matter fiber architecture of the brain (from \sphinxhref {http://www.humanconnectomeproject.org/gallery/}{Human Connectome Project})}}{5}{figure.1.3}\protected@file@percent }
\newlabel{docs/intro:connectome-fig}{{1.3}{5}{White matter fiber architecture of the brain (from \sphinxhref {http://www.humanconnectomeproject.org/gallery/}{Human Connectome Project})}{figure.1.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.3}Feed\sphinxhyphen {}forward networks}{5}{section.1.3}\protected@file@percent }
\newlabel{docs/intro:feed-forward-networks}{{1.3}{5}{Feed\sphinxhyphen {}forward networks}{section.1.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.4}{\ignorespaces A sample feed\sphinxhyphen {}foward fully connected artificial neural network. The blobs represent the neurons, and the edges indicate the synaptic connections between them. The signal propagates starting from the input (black dots), via the neurons in subsequent intermediate (hidden) layers (purple blobs) and the output layer (light blue blobs), to finally end up as the output (black dots). The strength of the connections is controled by weights (hyperparameters) assigned to the edges.}}{6}{figure.1.4}\protected@file@percent }
\newlabel{docs/intro:ffnn-fig}{{1.4}{6}{A sample feed\sphinxhyphen {}foward fully connected artificial neural network. The blobs represent the neurons, and the edges indicate the synaptic connections between them. The signal propagates starting from the input (black dots), via the neurons in subsequent intermediate (hidden) layers (purple blobs) and the output layer (light blue blobs), to finally end up as the output (black dots). The strength of the connections is controled by weights (hyperparameters) assigned to the edges}{figure.1.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.4}Why Python}{6}{section.1.4}\protected@file@percent }
\newlabel{docs/intro:why-python}{{1.4}{6}{Why Python}{section.1.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4.1}Imported packages}{7}{subsection.1.4.1}\protected@file@percent }
\newlabel{docs/intro:imported-packages}{{1.4.1}{7}{Imported packages}{subsection.1.4.1}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}MCP Neuron}{9}{chapter.2}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{docs/mcp:mcp-neuron}{{2}{9}{MCP Neuron}{chapter.2}{}}
\newlabel{docs/mcp:mcp-lab}{{2}{9}{MCP Neuron}{chapter.2}{}}
\newlabel{docs/mcp::doc}{{2}{9}{MCP Neuron}{chapter.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Definition}{9}{section.2.1}\protected@file@percent }
\newlabel{docs/mcp:definition}{{2.1}{9}{Definition}{section.2.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces MCP neuron: \(x_i\) are the inputs (different in each instance of the data), \(w_i\) are the weights, \(s\) is the signal, \(b\) is the bias, and \(f(s;b)\) represents the acitvation function, yielding the output \(y=f(s;b)\). The blue oval encircles the whole neuron, as used in \hyperref  [docs/intro:ffnn-fig]{Fig.\spacefactor \@m {} \ref  {docs/intro:ffnn-fig}}.}}{9}{figure.2.1}\protected@file@percent }
\newlabel{docs/mcp:mcp1-fig}{{2.1}{9}{MCP neuron: \(x_i\) are the inputs (different in each instance of the data), \(w_i\) are the weights, \(s\) is the signal, \(b\) is the bias, and \(f(s;b)\) represents the acitvation function, yielding the output \(y=f(s;b)\). The blue oval encircles the whole neuron, as used in \hyperref [\detokenize {docs/intro:ffnn-fig}]{Fig.\@ \ref {\detokenize {docs/intro:ffnn-fig}}}}{figure.2.1}{}}
\newlabel{equation:docs/mcp:eq-f}{{2.1}{10}{Definition}{equation.2.1.1}{}}
\newlabel{equation:docs/mcp:eq-f0}{{2.2}{10}{Definition}{equation.2.1.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Alternative, more uniform representation of the MCP neuron, with \(x_0=1\) and \(w_0=-b\).}}{10}{figure.2.2}\protected@file@percent }
\newlabel{docs/mcp:mcp2-fig}{{2.2}{10}{Alternative, more uniform representation of the MCP neuron, with \(x_0=1\) and \(w_0=-b\)}{figure.2.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}MCP neuron in Python}{11}{section.2.2}\protected@file@percent }
\newlabel{docs/mcp:mcp-neuron-in-python}{{2.2}{11}{MCP neuron in Python}{section.2.2}{}}
\newlabel{docs/mcp:mcp-p-lab}{{2.2}{11}{MCP neuron in Python}{section.2.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Boolean functions}{14}{section.2.3}\protected@file@percent }
\newlabel{docs/mcp:boolean-functions}{{2.3}{14}{Boolean functions}{section.2.3}{}}
\newlabel{docs/mcp:bool-sec}{{2.3}{14}{Boolean functions}{section.2.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.1}Problem with XOR}{15}{subsection.2.3.1}\protected@file@percent }
\newlabel{docs/mcp:problem-with-xor}{{2.3.1}{15}{Problem with XOR}{subsection.2.3.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.2}XOR from composition of AND, NAND and OR}{16}{subsection.2.3.2}\protected@file@percent }
\newlabel{docs/mcp:xor-from-composition-of-and-nand-and-or}{{2.3.2}{16}{XOR from composition of AND, NAND and OR}{subsection.2.3.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces The XOR gate compsed of the NAND, OR, and AND MCP neurons.}}{16}{figure.2.3}\protected@file@percent }
\newlabel{docs/mcp:xor-fig}{{2.3}{16}{The XOR gate compsed of the NAND, OR, and AND MCP neurons}{figure.2.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.3}XOR composed from NAND}{16}{subsection.2.3.3}\protected@file@percent }
\newlabel{docs/mcp:xor-composed-from-nand}{{2.3.3}{16}{XOR composed from NAND}{subsection.2.3.3}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Models of memory}{19}{chapter.3}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{docs/memory:models-of-memory}{{3}{19}{Models of memory}{chapter.3}{}}
\newlabel{docs/memory::doc}{{3}{19}{Models of memory}{chapter.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Heteroassociative memory}{19}{section.3.1}\protected@file@percent }
\newlabel{docs/memory:heteroassociative-memory}{{3.1}{19}{Heteroassociative memory}{section.3.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.1}Pair associations}{19}{subsection.3.1.1}\protected@file@percent }
\newlabel{docs/memory:pair-associations}{{3.1.1}{19}{Pair associations}{subsection.3.1.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.2}Memory matrix}{21}{subsection.3.1.2}\protected@file@percent }
\newlabel{docs/memory:memory-matrix}{{3.1.2}{21}{Memory matrix}{subsection.3.1.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.3}Applying a filter}{22}{subsection.3.1.3}\protected@file@percent }
\newlabel{docs/memory:applying-a-filter}{{3.1.3}{22}{Applying a filter}{subsection.3.1.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Autoassociative memory}{25}{section.3.2}\protected@file@percent }
\newlabel{docs/memory:autoassociative-memory}{{3.2}{25}{Autoassociative memory}{section.3.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.1}Self\sphinxhyphen {}associations}{25}{subsection.3.2.1}\protected@file@percent }
\newlabel{docs/memory:self-associations}{{3.2.1}{25}{Self\sphinxhyphen {}associations}{subsection.3.2.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.2}Distorting the image}{25}{subsection.3.2.2}\protected@file@percent }
\newlabel{docs/memory:distorting-the-image}{{3.2.2}{25}{Distorting the image}{subsection.3.2.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.3}Restoring the symbols}{26}{subsection.3.2.3}\protected@file@percent }
\newlabel{docs/memory:restoring-the-symbols}{{3.2.3}{26}{Restoring the symbols}{subsection.3.2.3}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Perceptron}{29}{chapter.4}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{docs/perceptron:perceptron}{{4}{29}{Perceptron}{chapter.4}{}}
\newlabel{docs/perceptron:perc-lab}{{4}{29}{Perceptron}{chapter.4}{}}
\newlabel{docs/perceptron::doc}{{4}{29}{Perceptron}{chapter.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Supervised learning}{29}{section.4.1}\protected@file@percent }
\newlabel{docs/perceptron:supervised-learning}{{4.1}{29}{Supervised learning}{section.4.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Binary classifier}{30}{section.4.2}\protected@file@percent }
\newlabel{docs/perceptron:binary-classifier}{{4.2}{30}{Binary classifier}{section.4.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.1}Sample with a known classification rule}{30}{subsection.4.2.1}\protected@file@percent }
\newlabel{docs/perceptron:sample-with-a-known-classification-rule}{{4.2.1}{30}{Sample with a known classification rule}{subsection.4.2.1}{}}
\newlabel{equation:docs/perceptron:eq-linsep}{{4.1}{31}{Sample with a known classification rule}{equation.4.2.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.2}Sample with an unknown classification rule}{32}{subsection.4.2.2}\protected@file@percent }
\newlabel{docs/perceptron:sample-with-an-unknown-classification-rule}{{4.2.2}{32}{Sample with an unknown classification rule}{subsection.4.2.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Perceptron algorithm}{33}{section.4.3}\protected@file@percent }
\newlabel{docs/perceptron:perceptron-algorithm}{{4.3}{33}{Perceptron algorithm}{section.4.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.1}Testing the classifier}{35}{subsection.4.3.1}\protected@file@percent }
\newlabel{docs/perceptron:testing-the-classifier}{{4.3.1}{35}{Testing the classifier}{subsection.4.3.1}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}More layers}{37}{chapter.5}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{docs/more_layers:more-layers}{{5}{37}{More layers}{chapter.5}{}}
\newlabel{docs/more_layers:more-lab}{{5}{37}{More layers}{chapter.5}{}}
\newlabel{docs/more_layers::doc}{{5}{37}{More layers}{chapter.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Two layers of neurons}{37}{section.5.1}\protected@file@percent }
\newlabel{docs/more_layers:two-layers-of-neurons}{{5.1}{37}{Two layers of neurons}{section.5.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.1}{\ignorespaces Sample convex regions in the plane obtained, from left to right, with one inequality condition, and a conjunction of 2, 3, or 4 inequality conditions, yielding \sphinxstylestrong {polygons}.}}{37}{figure.5.1}\protected@file@percent }
\newlabel{docs/more_layers:regions-fig}{{5.1}{37}{Sample convex regions in the plane obtained, from left to right, with one inequality condition, and a conjunction of 2, 3, or 4 inequality conditions, yielding \sphinxstylestrong {polygons}}{figure.5.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.2}{\ignorespaces Networks capable of classifying data in the corresponding regions of \hyperref  [docs/more_layers:regions-fig]{Fig.\spacefactor \@m {} \ref  {docs/more_layers:regions-fig}}.}}{38}{figure.5.2}\protected@file@percent }
\newlabel{docs/more_layers:nfn-fig}{{5.2}{38}{Networks capable of classifying data in the corresponding regions of \hyperref [\detokenize {docs/more_layers:regions-fig}]{Fig.\@ \ref {\detokenize {docs/more_layers:regions-fig}}}}{figure.5.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.2}Three or more layers of neurons}{38}{section.5.2}\protected@file@percent }
\newlabel{docs/more_layers:three-or-more-layers-of-neurons}{{5.2}{38}{Three or more layers of neurons}{section.5.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.3}{\ignorespaces Triangle with a tringular hollow.}}{39}{figure.5.3}\protected@file@percent }
\newlabel{docs/more_layers:tri-fig}{{5.3}{39}{Triangle with a tringular hollow}{figure.5.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.3}Feeding forward in Python}{39}{section.5.3}\protected@file@percent }
\newlabel{docs/more_layers:feeding-forward-in-python}{{5.3}{39}{Feeding forward in Python}{section.5.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.4}Visualization}{43}{section.5.4}\protected@file@percent }
\newlabel{docs/more_layers:visualization}{{5.4}{43}{Visualization}{section.5.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.5}Classifier with three neuron layers}{43}{section.5.5}\protected@file@percent }
\newlabel{docs/more_layers:classifier-with-three-neuron-layers}{{5.5}{43}{Classifier with three neuron layers}{section.5.5}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {6}Back propagation}{47}{chapter.6}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{docs/backprop:back-propagation}{{6}{47}{Back propagation}{chapter.6}{}}
\newlabel{docs/backprop::doc}{{6}{47}{Back propagation}{chapter.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6.1}Minimizing the error}{47}{section.6.1}\protected@file@percent }
\newlabel{docs/backprop:minimizing-the-error}{{6.1}{47}{Minimizing the error}{section.6.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6.2}Continuous activation function}{49}{section.6.2}\protected@file@percent }
\newlabel{docs/backprop:continuous-activation-function}{{6.2}{49}{Continuous activation function}{section.6.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6.3}Steepest descent}{53}{s