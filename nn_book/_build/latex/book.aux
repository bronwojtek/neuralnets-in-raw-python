\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand*\HyPL@Entry[1]{}
\HyPL@Entry{0<</S/D>>}
\selectlanguage *{english}
\@writefile{toc}{\selectlanguage *{english}}
\@writefile{lof}{\selectlanguage *{english}}
\@writefile{lot}{\selectlanguage *{english}}
\HyPL@Entry{2<</S/r>>}
\HyPL@Entry{4<</S/D>>}
\newlabel{docs/index::doc}{{}{1}{}{section*.2}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{3}{chapter.1}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{docs/intro:introduction}{{1}{3}{Introduction}{chapter.1}{}}
\newlabel{docs/intro::doc}{{1}{3}{Introduction}{chapter.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Purpose of these lectures}{3}{section.1.1}\protected@file@percent }
\newlabel{docs/intro:purpose-of-these-lectures}{{1.1}{3}{Purpose of these lectures}{section.1.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Biological inspiration}{3}{section.1.2}\protected@file@percent }
\newlabel{docs/intro:biological-inspiration}{{1.2}{3}{Biological inspiration}{section.1.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.1}{\ignorespaces Biological neuron (from \sphinxhref {https://training.seer.cancer.gov/anatomy/nervous/tissue.html}{here}).}}{4}{figure.1.1}\protected@file@percent }
\newlabel{docs/intro:neuron-fig}{{1.1}{4}{Biological neuron (from \sphinxhref {https://training.seer.cancer.gov/anatomy/nervous/tissue.html}{here})}{figure.1.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.2}{\ignorespaces A small brain sample with axons clearly visible (from \sphinxhref {https://www.dailykos.com/stories/2021/6/12/2034998/-Top-Comments-Most-Intensive-Study-of-Brain-Neuron-Connections-Reveals-Never-Before-Seen-Structures}{here})}}{5}{figure.1.2}\protected@file@percent }
\newlabel{docs/intro:sample-fig}{{1.2}{5}{A small brain sample with axons clearly visible (from \sphinxhref {https://www.dailykos.com/stories/2021/6/12/2034998/-Top-Comments-Most-Intensive-Study-of-Brain-Neuron-Connections-Reveals-Never-Before-Seen-Structures}{here})}{figure.1.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.3}{\ignorespaces White matter fiber architecture of the brain (from \sphinxhref {http://www.humanconnectomeproject.org/gallery/}{Human Connectome Project})}}{5}{figure.1.3}\protected@file@percent }
\newlabel{docs/intro:connectome-fig}{{1.3}{5}{White matter fiber architecture of the brain (from \sphinxhref {http://www.humanconnectomeproject.org/gallery/}{Human Connectome Project})}{figure.1.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.3}Feed\sphinxhyphen {}forward networks}{5}{section.1.3}\protected@file@percent }
\newlabel{docs/intro:feed-forward-networks}{{1.3}{5}{Feed\sphinxhyphen {}forward networks}{section.1.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.4}{\ignorespaces A sample feed\sphinxhyphen {}foward fully connected artificial neural network. The blobs represent the neurons, and the edges indicate the synaptic connections between them. The signal propagates starting from the input (black dots), via the neurons in subsequent intermediate (hidden) layers (purple blobs) and the output layer (light blue blobs), to finally end up as the output (black dots). The strength of the connections is controled by weights (hyperparameters) assigned to the edges.}}{6}{figure.1.4}\protected@file@percent }
\newlabel{docs/intro:ffnn-fig}{{1.4}{6}{A sample feed\sphinxhyphen {}foward fully connected artificial neural network. The blobs represent the neurons, and the edges indicate the synaptic connections between them. The signal propagates starting from the input (black dots), via the neurons in subsequent intermediate (hidden) layers (purple blobs) and the output layer (light blue blobs), to finally end up as the output (black dots). The strength of the connections is controled by weights (hyperparameters) assigned to the edges}{figure.1.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.4}Why Python}{6}{section.1.4}\protected@file@percent }
\newlabel{docs/intro:why-python}{{1.4}{6}{Why Python}{section.1.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4.1}Imported packages}{7}{subsection.1.4.1}\protected@file@percent }
\newlabel{docs/intro:imported-packages}{{1.4.1}{7}{Imported packages}{subsection.1.4.1}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}MCP Neuron}{9}{chapter.2}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{docs/mcp:mcp-neuron}{{2}{9}{MCP Neuron}{chapter.2}{}}
\newlabel{docs/mcp:mcp-lab}{{2}{9}{MCP Neuron}{chapter.2}{}}
\newlabel{docs/mcp::doc}{{2}{9}{MCP Neuron}{chapter.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Definition}{9}{section.2.1}\protected@file@percent }
\newlabel{docs/mcp:definition}{{2.1}{9}{Definition}{section.2.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces MCP neuron: \(x_i\) are the inputs (different in each instance of the data), \(w_i\) are the weights, \(s\) is the signal, \(b\) is the bias, and \(f(s;b)\) represents the acitvation function, yielding the output \(y=f(s;b)\). The blue oval encircles the whole neuron, as used in \hyperref  [docs/intro:ffnn-fig]{Fig.\spacefactor \@m {} \ref  {docs/intro:ffnn-fig}}.}}{9}{figure.2.1}\protected@file@percent }
\newlabel{docs/mcp:mcp1-fig}{{2.1}{9}{MCP neuron: \(x_i\) are the inputs (different in each instance of the data), \(w_i\) are the weights, \(s\) is the signal, \(b\) is the bias, and \(f(s;b)\) represents the acitvation function, yielding the output \(y=f(s;b)\). The blue oval encircles the whole neuron, as used in \hyperref [\detokenize {docs/intro:ffnn-fig}]{Fig.\@ \ref {\detokenize {docs/intro:ffnn-fig}}}}{figure.2.1}{}}
\newlabel{equation:docs/mcp:eq-f}{{2.1}{10}{Definition}{equation.2.1.1}{}}
\newlabel{equation:docs/mcp:eq-f0}{{2.2}{10}{Definition}{equation.2.1.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Alternative, more uniform representation of the MCP neuron, with \(x_0=1\) and \(w_0=-b\).}}{10}{figure.2.2}\protected@file@percent }
\newlabel{docs/mcp:mcp2-fig}{{2.2}{10}{Alternative, more uniform representation of the MCP neuron, with \(x_0=1\) and \(w_0=-b\)}{figure.2.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}MCP neuron in Python}{11}{section.2.2}\protected@file@percent }
\newlabel{docs/mcp:mcp-neuron-in-python}{{2.2}{11}{MCP neuron in Python}{section.2.2}{}}
\newlabel{docs/mcp:mcp-p-lab}{{2.2}{11}{MCP neuron in Python}{section.2.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Boolean functions}{14}{section.2.3}\protected@file@percent }
\newlabel{docs/mcp:boolean-functions}{{2.3}{14}{Boolean functions}{section.2.3}{}}
\newlabel{docs/mcp:bool-sec}{{2.3}{14}{Boolean functions}{section.2.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.1}Problem with XOR}{15}{subsection.2.3.1}\protected@file@percent }
\newlabel{docs/mcp:problem-with-xor}{{2.3.1}{15}{Problem with XOR}{subsection.2.3.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.2}XOR from composition of AND, NAND and OR}{16}{subsection.2.3.2}\protected@file@percent }
\newlabel{docs/mcp:xor-from-composition-of-and-nand-and-or}{{2.3.2}{16}{XOR from composition of AND, NAND and OR}{subsection.2.3.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces The XOR gate compsed of the NAND, OR, and AND MCP neurons.}}{16}{figure.2.3}\protected@file@percent }
\newlabel{docs/mcp:xor-fig}{{2.3}{16}{The XOR gate compsed of the NAND, OR, and AND MCP neurons}{figure.2.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.3}XOR composed from NAND}{16}{subsection.2.3.3}\protected@file@percent }
\newlabel{docs/mcp:xor-composed-from-nand}{{2.3.3}{16}{XOR composed from NAND}{subsection.2.3.3}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Models of memory}{19}{chapter.3}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{docs/memory:models-of-memory}{{3}{19}{Models of memory}{chapter.3}{}}
\newlabel{docs/memory::doc}{{3}{19}{Models of memory}{chapter.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Heteroassociative memory}{19}{section.3.1}\protected@file@percent }
\newlabel{docs/memory:heteroassociative-memory}{{3.1}{19}{Heteroassociative memory}{section.3.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.1}Pair associations}{19}{subsection.3.1.1}\protected@file@percent }
\newlabel{docs/memory:pair-associations}{{3.1.1}{19}{Pair associations}{subsection.3.1.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.2}Memory matrix}{21}{subsection.3.1.2}\protected@file@percent }
\newlabel{docs/memory:memory-matrix}{{3.1.2}{21}{Memory matrix}{subsection.3.1.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.3}Applying a filter}{22}{subsection.3.1.3}\protected@file@percent }
\newlabel{docs/memory:applying-a-filter}{{3.1.3}{22}{Applying a filter}{subsection.3.1.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Autoassociative memory}{25}{section.3.2}\protected@file@percent }
\newlabel{docs/memory:autoassociative-memory}{{3.2}{25}{Autoassociative memory}{section.3.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.1}Self\sphinxhyphen {}associations}{25}{subsection.3.2.1}\protected@file@percent }
\newlabel{docs/memory:self-associations}{{3.2.1}{25}{Self\sphinxhyphen {}associations}{subsection.3.2.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.2}Distorting the image}{25}{subsection.3.2.2}\protected@file@percent }
\newlabel{docs/memory:distorting-the-image}{{3.2.2}{25}{Distorting the image}{subsection.3.2.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.3}Restoring the symbols}{26}{subsection.3.2.3}\protected@file@percent }
\newlabel{docs/memory:restoring-the-symbols}{{3.2.3}{26}{Restoring the symbols}{subsection.3.2.3}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Perceptron}{29}{chapter.4}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{docs/perceptron:perceptron}{{4}{29}{Perceptron}{chapter.4}{}}
\newlabel{docs/perceptron:perc-lab}{{4}{29}{Perceptron}{chapter.4}{}}
\newlabel{docs/perceptron::doc}{{4}{29}{Perceptron}{chapter.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Supervised learning}{29}{section.4.1}\protected@file@percent }
\newlabel{docs/perceptron:supervised-learning}{{4.1}{29}{Supervised learning}{section.4.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Binary classifier}{30}{section.4.2}\protected@file@percent }
\newlabel{docs/perceptron:binary-classifier}{{4.2}{30}{Binary classifier}{section.4.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.1}Sample with a known classification rule}{30}{subsection.4.2.1}\protected@file@percent }
\newlabel{docs/perceptron:sample-with-a-known-classification-rule}{{4.2.1}{30}{Sample with a known classification rule}{subsection.4.2.1}{}}
\newlabel{equation:docs/perceptron:eq-linsep}{{4.1}{31}{Sample with a known classification rule}{equation.4.2.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.2}Sample with an unknown classification rule}{32}{subsection.4.2.2}\protected@file@percent }
\newlabel{docs/perceptron:sample-with-an-unknown-classification-rule}{{4.2.2}{32}{Sample with an unknown classification rule}{subsection.4.2.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Perceptron algorithm}{33}{section.4.3}\protected@file@percent }
\newlabel{docs/perceptron:perceptron-algorithm}{{4.3}{33}{Perceptron algorithm}{section.4.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.1}Testing the classifier}{35}{subsection.4.3.1}\protected@file@percent }
\newlabel{docs/perceptron:testing-the-classifier}{{4.3.1}{35}{Testing the classifier}{subsection.4.3.1}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}More layers}{37}{chapter.5}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{docs/more_layers:more-layers}{{5}{37}{More layers}{chapter.5}{}}
\newlabel{docs/more_layers:more-lab}{{5}{37}{More layers}{chapter.5}{}}
\newlabel{docs/more_layers::doc}{{5}{37}{More layers}{chapter.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Two layers of neurons}{37}{section.5.1}\protected@file@percent }
\newlabel{docs/more_layers:two-layers-of-neurons}{{5.1}{37}{Two layers of neurons}{section.5.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.1}{\ignorespaces Sample convex regions in the plane obtained, from left to right, with one inequality condition, and a conjunction of 2, 3, or 4 inequality conditions, yielding \sphinxstylestrong {polygons}.}}{37}{figure.5.1}\protected@file@percent }
\newlabel{docs/more_layers:regions-fig}{{5.1}{37}{Sample convex regions in the plane obtained, from left to right, with one inequality condition, and a conjunction of 2, 3, or 4 inequality conditions, yielding \sphinxstylestrong {polygons}}{figure.5.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.2}{\ignorespaces Networks capable of classifying data in the corresponding regions of \hyperref  [docs/more_layers:regions-fig]{Fig.\spacefactor \@m {} \ref  {docs/more_layers:regions-fig}}.}}{38}{figure.5.2}\protected@file@percent }
\newlabel{docs/more_layers:nfn-fig}{{5.2}{38}{Networks capable of classifying data in the corresponding regions of \hyperref [\detokenize {docs/more_layers:regions-fig}]{Fig.\@ \ref {\detokenize {docs/more_layers:regions-fig}}}}{figure.5.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.2}Three or more layers of neurons}{38}{section.5.2}\protected@file@percent }
\newlabel{docs/more_layers:three-or-more-layers-of-neurons}{{5.2}{38}{Three or more layers of neurons}{section.5.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.3}{\ignorespaces Triangle with a tringular hollow.}}{39}{figure.5.3}\protected@file@percent }
\newlabel{docs/more_layers:tri-fig}{{5.3}{39}{Triangle with a tringular hollow}{figure.5.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.3}Feeding forward in Python}{39}{section.5.3}\protected@file@percent }
\newlabel{docs/more_layers:feeding-forward-in-python}{{5.3}{39}{Feeding forward in Python}{section.5.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.4}Visualization}{43}{section.5.4}\protected@file@percent }
\newlabel{docs/more_layers:visualization}{{5.4}{43}{Visualization}{section.5.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.5}Classifier with three neuron layers}{43}{section.5.5}\protected@file@percent }
\newlabel{docs/more_layers:classifier-with-three-neuron-layers}{{5.5}{43}{Classifier with three neuron layers}{section.5.5}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {6}Back propagation}{47}{chapter.6}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{docs/backprop:back-propagation}{{6}{47}{Back propagation}{chapter.6}{}}
\newlabel{docs/backprop::doc}{{6}{47}{Back propagation}{chapter.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6.1}Minimizing the error}{47}{section.6.1}\protected@file@percent }
\newlabel{docs/backprop:minimizing-the-error}{{6.1}{47}{Minimizing the error}{section.6.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6.2}Continuous activation function}{49}{section.6.2}\protected@file@percent }
\newlabel{docs/backprop:continuous-activation-function}{{6.2}{49}{Continuous activation function}{section.6.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6.3}Steepest descent}{53}{section.6.3}\protected@file@percent }
\newlabel{docs/backprop:steepest-descent}{{6.3}{53}{Steepest descent}{section.6.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6.4}Backprop algorithm}{55}{section.6.4}\protected@file@percent }
\newlabel{docs/backprop:backprop-algorithm}{{6.4}{55}{Backprop algorithm}{section.6.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.4.1}Code for backprop}{57}{subsection.6.4.1}\protected@file@percent }
\newlabel{docs/backprop:code-for-backprop}{{6.4.1}{57}{Code for backprop}{subsection.6.4.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6.5}Example with the circle}{58}{section.6.5}\protected@file@percent }
\newlabel{docs/backprop:example-with-the-circle}{{6.5}{58}{Example with the circle}{section.6.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6.6}General remarks}{61}{section.6.6}\protected@file@percent }
\newlabel{docs/backprop:general-remarks}{{6.6}{61}{General remarks}{section.6.6}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {7}Interpolation}{63}{chapter.7}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{docs/interpol:interpolation}{{7}{63}{Interpolation}{chapter.7}{}}
\newlabel{docs/interpol::doc}{{7}{63}{Interpolation}{chapter.7}{}}
\@writefile{toc}{\contentsline {section}{\numberline {7.1}Simulated data}{63}{section.7.1}\protected@file@percent }
\newlabel{docs/interpol:simulated-data}{{7.1}{63}{Simulated data}{section.7.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {7.2}ANNs for interpolation}{64}{section.7.2}\protected@file@percent }
\newlabel{docs/interpol:anns-for-interpolation}{{7.2}{64}{ANNs for interpolation}{section.7.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2.1}Backprop for one\sphinxhyphen {}dimensional functions}{66}{subsection.7.2.1}\protected@file@percent }
\newlabel{docs/interpol:backprop-for-one-dimensional-functions}{{7.2.1}{66}{Backprop for one\sphinxhyphen {}dimensional functions}{subsection.7.2.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {7.3}Remarks}{67}{section.7.3}\protected@file@percent }
\newlabel{docs/interpol:remarks}{{7.3}{67}{Remarks}{section.7.3}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {8}Rectification}{69}{chapter.8}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{docs/rectification:rectification}{{8}{69}{Rectification}{chapter.8}{}}
\newlabel{docs/rectification::doc}{{8}{69}{Rectification}{chapter.8}{}}
\@writefile{toc}{\contentsline {section}{\numberline {8.1}Interpolation with ReLU}{70}{section.8.1}\protected@file@percent }
\newlabel{docs/rectification:interpolation-with-relu}{{8.1}{70}{Interpolation with ReLU}{section.8.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {8.2}Classifiers with rectification}{71}{section.8.2}\protected@file@percent }
\newlabel{docs/rectification:classifiers-with-rectification}{{8.2}{71}{Classifiers with rectification}{section.8.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {8.3}General remarks on backprop}{72}{section.8.3}\protected@file@percent }
\newlabel{docs/rectification:general-remarks-on-backprop}{{8.3}{72}{General remarks on backprop}{section.8.3}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {9}Unsupervised learning}{75}{chapter.9}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{docs/unsupervised:unsupervised-learning}{{9}{75}{Unsupervised learning}{chapter.9}{}}
\newlabel{docs/unsupervised:un-lab}{{9}{75}{Unsupervised learning}{chapter.9}{}}
\newlabel{docs/unsupervised::doc}{{9}{75}{Unsupervised learning}{chapter.9}{}}
\@writefile{toc}{\contentsline {section}{\numberline {9.1}Clusters of points}{75}{section.9.1}\protected@file@percent }
\newlabel{docs/unsupervised:clusters-of-points}{{9.1}{75}{Clusters of points}{section.9.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {9.2}Voronoi areas}{77}{section.9.2}\protected@file@percent }
\newlabel{docs/unsupervised:voronoi-areas}{{9.2}{77}{Voronoi areas}{section.9.2}{}}
\newlabel{docs/unsupervised:vor-lab}{{9.2}{77}{Voronoi areas}{section.9.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {9.3}Naive clusterization}{78}{section.9.3}\protected@file@percent }
\newlabel{docs/unsupervised:naive-clusterization}{{9.3}{78}{Naive clusterization}{section.9.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9.1}{\ignorespaces Left: proper characteristic points. Right: one “dead body”.}}{82}{figure.9.1}\protected@file@percent }
\newlabel{docs/unsupervised:p-fig}{{9.1}{82}{Left: proper characteristic points. Right: one “dead body”}{figure.9.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9.2}{\ignorespaces From left to right: 5 characteristic points with one cluster split into two, with another cluster split into two, one dead body, and two dead bodies.}}{82}{figure.9.2}\protected@file@percent }
\newlabel{docs/unsupervised:id1}{{9.2}{82}{From left to right: 5 characteristic points with one cluster split into two, with another cluster split into two, one dead body, and two dead bodies}{figure.9.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {9.4}Clustering scale}{83}{section.9.4}\protected@file@percent }
\newlabel{docs/unsupervised:clustering-scale}{{9.4}{83}{Clustering scale}{section.9.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9.3}{\ignorespaces Dynamical clustering for various values of the scale \(d\).}}{84}{figure.9.3}\protected@file@percent }
\newlabel{docs/unsupervised:dyn-fig}{{9.3}{84}{Dynamical clustering for various values of the scale \(d\)}{figure.9.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.4.1}Interpretation via steepest descent}{85}{subsection.9.4.1}\protected@file@percent }
\newlabel{docs/unsupervised:interpretation-via-steepest-descent}{{9.4.1}{85}{Interpretation via steepest descent}{subsection.9.4.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {9.5}Interpretation via neural networks}{86}{section.9.5}\protected@file@percent }
\newlabel{docs/unsupervised:interpretation-via-neural-networks}{{9.5}{86}{Interpretation via neural networks}{section.9.5}{}}
\newlabel{docs/unsupervised:inn-sec}{{9.5}{86}{Interpretation via neural networks}{section.9.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.5.1}Representation with spherical coordinates}{86}{subsection.9.5.1}\protected@file@percent }
\newlabel{docs/unsupervised:representation-with-spherical-coordinates}{{9.5.1}{86}{Representation with spherical coordinates}{subsection.9.5.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.5.2}Scalar product maximization}{88}{subsection.9.5.2}\protected@file@percent }
\newlabel{docs/unsupervised:scalar-product-maximization}{{9.5.2}{88}{Scalar product maximization}{subsection.9.5.2}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {10}Self Organizing Maps}{91}{chapter.10}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{docs/som:self-organizing-maps}{{10}{91}{Self Organizing Maps}{chapter.10}{}}
\newlabel{docs/som::doc}{{10}{91}{Self Organizing Maps}{chapter.10}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10.1}{\ignorespaces Example of Kohonen networks. Left: 1\sphinxhyphen {}dim. grid of neurons \(N\) and 2\sphinxhyphen {}dim. input space \(D\). Right: 2\sphinxhyphen {}dim. grid of neurons \(N\) and 3\sphinxhyphen {}dim. input space \(D\). The red dot indicates the winner, and the gray oval marks its neighborhood.}}{91}{figure.10.1}\protected@file@percent }
\newlabel{docs/som:koh-fig}{{10.1}{91}{Example of Kohonen networks. Left: 1\sphinxhyphen {}dim. grid of neurons \(N\) and 2\sphinxhyphen {}dim. input space \(D\). Right: 2\sphinxhyphen {}dim. grid of neurons \(N\) and 3\sphinxhyphen {}dim. input space \(D\). The red dot indicates the winner, and the gray oval marks its neighborhood}{figure.10.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {10.1}Kohonen’s algorithm}{92}{section.10.1}\protected@file@percent }
\newlabel{docs/som:kohonen-s-algorithm}{{10.1}{92}{Kohonen’s algorithm}{section.10.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {10.1.1}2\sphinxhyphen {}dim. data and 1\sphinxhyphen {}dim. neuron grid}{92}{subsection.10.1.1}\protected@file@percent }
\newlabel{docs/som:dim-data-and-1-dim-neuron-grid}{{10.1.1}{92}{2\sphinxhyphen {}dim. data and 1\sphinxhyphen {}dim. neuron grid}{subsection.10.1.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10.2}{\ignorespaces Progress of Kohonen’s algorithm. The lines, drawn to guide the eye, connects neurons with adjacent indices.}}{94}{figure.10.2}\protected@file@percent }
\newlabel{docs/som:kohstory-fig}{{10.2}{94}{Progress of Kohonen’s algorithm. The lines, drawn to guide the eye, connects neurons with adjacent indices}{figure.10.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {10.1.2}2 dim. color map}{96}{subsection.10.1.2}\protected@file@percent }
\newlabel{docs/som:dim-color-map}{{10.1.2}{96}{2 dim. color map}{subsection.10.1.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {10.2}U\sphinxhyphen {}matrix}{98}{section.10.2}\protected@file@percent }
\newlabel{docs/som:u-matrix}{{10.2}{98}{U\sphinxhyphen {}matrix}{section.10.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10.3}{\ignorespaces Construction of \(U_{ij}\): geometric average of the distance along the indicated links.}}{98}{figure.10.3}\protected@file@percent }
\newlabel{docs/som:udm-fig}{{10.3}{98}{Construction of \(U_{ij}\): geometric average of the distance along the indicated links}{figure.10.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {10.2.1}Mapping colors on a line}{101}{subsection.10.2.1}\protected@file@percent }
\newlabel{docs/som:mapping-colors-on-a-line}{{10.2.1}{101}{Mapping colors on a line}{subsection.10.2.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {10.2.2}Wikipedia articles’ similarity}{103}{subsection.10.2.2}\protected@file@percent }
\newlabel{docs/som:wikipedia-articles-similarity}{{10.2.2}{103}{Wikipedia articles’ similarity}{subsection.10.2.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {10.3}Mapping 2\sphinxhyphen {}dim. data into a 2\sphinxhyphen {}dim. grid}{104}{section.10.3}\protected@file@percent }
\newlabel{docs/som:mapping-2-dim-data-into-a-2-dim-grid}{{10.3}{104}{Mapping 2\sphinxhyphen {}dim. data into a 2\sphinxhyphen {}dim. grid}{section.10.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10.4}{\ignorespaces Progress of Kohonen’s algorithm. The lines, drawn to guide the eye, connects neurons with adjacent indices.}}{106}{figure.10.4}\protected@file@percent }
\newlabel{docs/som:kohstory2-fig}{{10.4}{106}{Progress of Kohonen’s algorithm. The lines, drawn to guide the eye, connects neurons with adjacent indices}{figure.10.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {10.4}Topological properties}{107}{section.10.4}\protected@file@percent }
\newlabel{docs/som:topological-properties}{{10.4}{107}{Topological properties}{section.10.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {10.5}Lateral inhibition}{109}{section.10.5}\protected@file@percent }
\newlabel{docs/som:lateral-inhibition}{{10.5}{109}{Lateral inhibition}{section.10.5}{}}
\newlabel{equation:docs/som:eq-lat}{{10.1}{109}{Lateral inhibition}{equation.10.5.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10.5}{\ignorespaces Network with inter\sphinxhyphen {}neuron coupling used for modeling lateral inhibition. All the neurons are connected in both directions (lines without arrows).}}{110}{figure.10.5}\protected@file@percent }
\newlabel{docs/som:lat-fig}{{10.5}{110}{Network with inter\sphinxhyphen {}neuron coupling used for modeling lateral inhibition. All the neurons are connected in both directions (lines without arrows)}{figure.10.5}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {11}Concluding remarks}{113}{chapter.11}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{docs/conclusion:concluding-remarks}{{11}{113}{Concluding remarks}{chapter.11}{}}
\newlabel{docs/conclusion::doc}{{11}{113}{Concluding remarks}{chapter.11}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {12}Appendix}{115}{chapter.12}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{docs/lib_app:appendix}{{12}{115}{Appendix}{chapter.12}{}}
\newlabel{docs/lib_app:app-lab}{{12}{115}{Appendix}{chapter.12}{}}
\newlabel{docs/lib_app::doc}{{12}{115}{Appendix}{chapter.12}{}}
\@writefile{toc}{\contentsline {section}{\numberline {12.1}\sphinxstylestrong {neural} package}{115}{section.12.1}\protected@file@percent }
\newlabel{docs/lib_app:neural-package}{{12.1}{115}{\sphinxstylestrong {neural} package}{section.12.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {12.1.1}\sphinxstylestrong {func.py} module}{115}{subsection.12.1.1}\protected@file@percent }
\newlabel{docs/lib_app:func-py-module}{{12.1.1}{115}{\sphinxstylestrong {func.py} module}{subsection.12.1.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {12.1.2}\sphinxstylestrong {draw.py} module}{121}{subsection.12.1.2}\protected@file@percent }
\newlabel{docs/lib_app:draw-py-module}{{12.1.2}{121}{\sphinxstylestrong {draw.py} module}{subsection.12.1.2}{}}
\bibcite{docs/conclusion:id2}{Gut16}
\@writefile{toc}{\contentsline {chapter}{Bibliography}{127}{chapter*.3}\protected@file@percent }
