\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand*\HyPL@Entry[1]{}
\HyPL@Entry{0<</S/D>>}
\selectlanguage *{english}
\@writefile{toc}{\selectlanguage *{english}}
\@writefile{lof}{\selectlanguage *{english}}
\@writefile{lot}{\selectlanguage *{english}}
\HyPL@Entry{2<</S/r>>}
\HyPL@Entry{4<</S/D>>}
\newlabel{docs/index::doc}{{}{1}{}{section*.2}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{3}{chapter.1}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{docs/intro:introduction}{{1}{3}{Introduction}{chapter.1}{}}
\newlabel{docs/intro::doc}{{1}{3}{Introduction}{chapter.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Purpose of these lectures}{3}{section.1.1}\protected@file@percent }
\newlabel{docs/intro:purpose-of-these-lectures}{{1.1}{3}{Purpose of these lectures}{section.1.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Biological inspiration}{4}{section.1.2}\protected@file@percent }
\newlabel{docs/intro:biological-inspiration}{{1.2}{4}{Biological inspiration}{section.1.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.1}{\ignorespaces Biological neuron (from \sphinxurl {https://training.seer.cancer.gov/anatomy/nervous/tissue.html}).}}{4}{figure.1.1}\protected@file@percent }
\newlabel{docs/intro:neuron-fig}{{1.1}{4}{Biological neuron (from \sphinxurl {https://training.seer.cancer.gov/anatomy/nervous/tissue.html})}{figure.1.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.2}{\ignorespaces White matter fiber architecture of the brain (from the Human Connectome Project \sphinxhref {http://www.humanconnectomeproject.org/gallery/}{humanconnectomeproject.org})}}{5}{figure.1.2}\protected@file@percent }
\newlabel{docs/intro:connectome-fig}{{1.2}{5}{White matter fiber architecture of the brain (from the Human Connectome Project \sphinxhref {http://www.humanconnectomeproject.org/gallery/}{humanconnectomeproject.org})}{figure.1.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.3}Feed\sphinxhyphen {}forward networks}{5}{section.1.3}\protected@file@percent }
\newlabel{docs/intro:feed-forward-networks}{{1.3}{5}{Feed\sphinxhyphen {}forward networks}{section.1.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.3}{\ignorespaces A sample feed\sphinxhyphen {}foward fully connected artificial neural network. The colored blobs represent the neurons, and the edges indicate the synaptic connections. The signal propagates starting from the input (black dots), via the neurons in subsequent intermediate (hidden) layers (purple blobs), to the output layer (light blue blobs). The strength of the connections is controled by weights (hyperparameters) assigned to the edges.}}{6}{figure.1.3}\protected@file@percent }
\newlabel{docs/intro:ffnn-fig}{{1.3}{6}{A sample feed\sphinxhyphen {}foward fully connected artificial neural network. The colored blobs represent the neurons, and the edges indicate the synaptic connections. The signal propagates starting from the input (black dots), via the neurons in subsequent intermediate (hidden) layers (purple blobs), to the output layer (light blue blobs). The strength of the connections is controled by weights (hyperparameters) assigned to the edges}{figure.1.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.4}Why Python}{6}{section.1.4}\protected@file@percent }
\newlabel{docs/intro:why-python}{{1.4}{6}{Why Python}{section.1.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4.1}Imported packages}{7}{subsection.1.4.1}\protected@file@percent }
\newlabel{docs/intro:imported-packages}{{1.4.1}{7}{Imported packages}{subsection.1.4.1}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}MCP Neuron}{9}{chapter.2}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{docs/mcp:mcp-neuron}{{2}{9}{MCP Neuron}{chapter.2}{}}
\newlabel{docs/mcp:mcp-lab}{{2}{9}{MCP Neuron}{chapter.2}{}}
\newlabel{docs/mcp::doc}{{2}{9}{MCP Neuron}{chapter.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Definition}{9}{section.2.1}\protected@file@percent }
\newlabel{docs/mcp:definition}{{2.1}{9}{Definition}{section.2.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces MCP neuron: \(x_i\) is the input, \(w_i\) are the weights, \(s\) is the signal, \(b\) is the bias, and \(f(s;b)\) represents an activation function, yielding the output \(y=f(s;b)\). The blue oval encircles the whole neuron, as used e.g. in \hyperref  [docs/intro:ffnn-fig]{Fig.\spacefactor \@m {} \ref  {docs/intro:ffnn-fig}}.}}{9}{figure.2.1}\protected@file@percent }
\newlabel{docs/mcp:mcp1-fig}{{2.1}{9}{MCP neuron: \(x_i\) is the input, \(w_i\) are the weights, \(s\) is the signal, \(b\) is the bias, and \(f(s;b)\) represents an activation function, yielding the output \(y=f(s;b)\). The blue oval encircles the whole neuron, as used e.g. in \hyperref [\detokenize {docs/intro:ffnn-fig}]{Fig.\@ \ref {\detokenize {docs/intro:ffnn-fig}}}}{figure.2.1}{}}
\newlabel{equation:docs/mcp:eq-f}{{2.1}{10}{Definition}{equation.2.1.1}{}}
\newlabel{equation:docs/mcp:eq-f0}{{2.2}{10}{Definition}{equation.2.1.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Alternative, more uniform representation of the MCP neuron, with \(x_0=1\) and \(w_0=-b\).}}{10}{figure.2.2}\protected@file@percent }
\newlabel{docs/mcp:mcp2-fig}{{2.2}{10}{Alternative, more uniform representation of the MCP neuron, with \(x_0=1\) and \(w_0=-b\)}{figure.2.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}MCP neuron in Python}{10}{section.2.2}\protected@file@percent }
\newlabel{docs/mcp:mcp-neuron-in-python}{{2.2}{10}{MCP neuron in Python}{section.2.2}{}}
\newlabel{docs/mcp:mcp-p-lab}{{2.2}{10}{MCP neuron in Python}{section.2.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Boolean functions}{13}{section.2.3}\protected@file@percent }
\newlabel{docs/mcp:boolean-functions}{{2.3}{13}{Boolean functions}{section.2.3}{}}
\newlabel{docs/mcp:bool-sec}{{2.3}{13}{Boolean functions}{section.2.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.1}Problem with XOR}{14}{subsection.2.3.1}\protected@file@percent }
\newlabel{docs/mcp:problem-with-xor}{{2.3.1}{14}{Problem with XOR}{subsection.2.3.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.2}XOR from composition of AND, NAND and OR}{15}{subsection.2.3.2}\protected@file@percent }
\newlabel{docs/mcp:xor-from-composition-of-and-nand-and-or}{{2.3.2}{15}{XOR from composition of AND, NAND and OR}{subsection.2.3.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces The XOR gate composed of the NAND, OR, and AND MCP neurons.}}{15}{figure.2.3}\protected@file@percent }
\newlabel{docs/mcp:xor-fig}{{2.3}{15}{The XOR gate composed of the NAND, OR, and AND MCP neurons}{figure.2.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.3}XOR composed from NAND}{16}{subsection.2.3.3}\protected@file@percent }
\newlabel{docs/mcp:xor-composed-from-nand}{{2.3.3}{16}{XOR composed from NAND}{subsection.2.3.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.4}Exercises}{16}{section.2.4}\protected@file@percent }
\newlabel{docs/mcp:exercises}{{2.4}{16}{Exercises}{section.2.4}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Models of memory}{17}{chapter.3}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{docs/memory:models-of-memory}{{3}{17}{Models of memory}{chapter.3}{}}
\newlabel{docs/memory::doc}{{3}{17}{Models of memory}{chapter.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Heteroassociative memory}{17}{section.3.1}\protected@file@percent }
\newlabel{docs/memory:heteroassociative-memory}{{3.1}{17}{Heteroassociative memory}{section.3.1}{}}
\newlabel{docs/memory:het-lab}{{3.1}{17}{Heteroassociative memory}{section.3.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.1}Pair associations}{17}{subsection.3.1.1}\protected@file@percent }
\newlabel{docs/memory:pair-associations}{{3.1.1}{17}{Pair associations}{subsection.3.1.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.2}Memory matrix}{19}{subsection.3.1.2}\protected@file@percent }
\newlabel{docs/memory:memory-matrix}{{3.1.2}{19}{Memory matrix}{subsection.3.1.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.3}Applying a filter}{20}{subsection.3.1.3}\protected@file@percent }
\newlabel{docs/memory:applying-a-filter}{{3.1.3}{20}{Applying a filter}{subsection.3.1.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Autoassociative memory}{22}{section.3.2}\protected@file@percent }
\newlabel{docs/memory:autoassociative-memory}{{3.2}{22}{Autoassociative memory}{section.3.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.1}Self\sphinxhyphen {}associations}{22}{subsection.3.2.1}\protected@file@percent }
\newlabel{docs/memory:self-associations}{{3.2.1}{22}{Self\sphinxhyphen {}associations}{subsection.3.2.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.2}Distorting the image}{23}{subsection.3.2.2}\protected@file@percent }
\newlabel{docs/memory:distorting-the-image}{{3.2.2}{23}{Distorting the image}{subsection.3.2.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.3}Restoring the symbols}{23}{subsection.3.2.3}\protected@file@percent }
\newlabel{docs/memory:restoring-the-symbols}{{3.2.3}{23}{Restoring the symbols}{subsection.3.2.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Exercises}{24}{section.3.3}\protected@file@percent }
\newlabel{docs/memory:exercises}{{3.3}{24}{Exercises}{section.3.3}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Perceptron}{25}{chapter.4}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{docs/perceptron:perceptron}{{4}{25}{Perceptron}{chapter.4}{}}
\newlabel{docs/perceptron:perc-lab}{{4}{25}{Perceptron}{chapter.4}{}}
\newlabel{docs/perceptron::doc}{{4}{25}{Perceptron}{chapter.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Supervised learning}{25}{section.4.1}\protected@file@percent }
\newlabel{docs/perceptron:supervised-learning}{{4.1}{25}{Supervised learning}{section.4.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Perceptron as a binary classifier}{26}{section.4.2}\protected@file@percent }
\newlabel{docs/perceptron:perceptron-as-a-binary-classifier}{{4.2}{26}{Perceptron as a binary classifier}{section.4.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.1}Sample with a known classification rule}{26}{subsection.4.2.1}\protected@file@percent }
\newlabel{docs/perceptron:sample-with-a-known-classification-rule}{{4.2.1}{26}{Sample with a known classification rule}{subsection.4.2.1}{}}
\newlabel{equation:docs/perceptron:eq-linsep}{{4.1}{27}{Sample with a known classification rule}{equation.4.2.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.2}Sample with an unknown classification rule}{28}{subsection.4.2.2}\protected@file@percent }
\newlabel{docs/perceptron:sample-with-an-unknown-classification-rule}{{4.2.2}{28}{Sample with an unknown classification rule}{subsection.4.2.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Perceptron algorithm}{29}{section.4.3}\protected@file@percent }
\newlabel{docs/perceptron:perceptron-algorithm}{{4.3}{29}{Perceptron algorithm}{section.4.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.1}Testing the classifier}{31}{subsection.4.3.1}\protected@file@percent }
\newlabel{docs/perceptron:testing-the-classifier}{{4.3.1}{31}{Testing the classifier}{subsection.4.3.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.4}Exercises}{32}{section.4.4}\protected@file@percent }
\newlabel{docs/perceptron:exercises}{{4.4}{32}{Exercises}{section.4.4}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}More layers}{33}{chapter.5}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{docs/more_layers:more-layers}{{5}{33}{More layers}{chapter.5}{}}
\newlabel{docs/more_layers:more-lab}{{5}{33}{More layers}{chapter.5}{}}
\newlabel{docs/more_layers::doc}{{5}{33}{More layers}{chapter.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Two layers of neurons}{33}{section.5.1}\protected@file@percent }
\newlabel{docs/more_layers:two-layers-of-neurons}{{5.1}{33}{Two layers of neurons}{section.5.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.1}{\ignorespaces Sample convex regions in the plane obtained, from left to right, with one inequality condition, and a conjunctions of 2, 3, or 4 inequality conditions, yielding \sphinxstylestrong {polygons}.}}{33}{figure.5.1}\protected@file@percent }
\newlabel{docs/more_layers:regions-fig}{{5.1}{33}{Sample convex regions in the plane obtained, from left to right, with one inequality condition, and a conjunctions of 2, 3, or 4 inequality conditions, yielding \sphinxstylestrong {polygons}}{figure.5.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.2}{\ignorespaces Networks capable of classifying data in the corresponding regions of \hyperref  [docs/more_layers:regions-fig]{Fig.\spacefactor \@m {} \ref  {docs/more_layers:regions-fig}}.}}{34}{figure.5.2}\protected@file@percent }
\newlabel{docs/more_layers:nfn-fig}{{5.2}{34}{Networks capable of classifying data in the corresponding regions of \hyperref [\detokenize {docs/more_layers:regions-fig}]{Fig.\@ \ref {\detokenize {docs/more_layers:regions-fig}}}}{figure.5.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.2}Three or more layers of neurons}{34}{section.5.2}\protected@file@percent }
\newlabel{docs/more_layers:three-or-more-layers-of-neurons}{{5.2}{34}{Three or more layers of neurons}{section.5.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.3}{\ignorespaces Triangle with a tringular hollow.}}{35}{figure.5.3}\protected@file@percent }
\newlabel{docs/more_layers:tri-fig}{{5.3}{35}{Triangle with a tringular hollow}{figure.5.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.3}Feeding forward in Python}{35}{section.5.3}\protected@file@percent }
\newlabel{docs/more_layers:feeding-forward-in-python}{{5.3}{35}{Feeding forward in Python}{section.5.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.4}Visualization}{38}{section.5.4}\protected@file@percent }
\newlabel{docs/more_layers:visualization}{{5.4}{38}{Visualization}{section.5.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.5}Classifier with three neuron layers}{39}{section.5.5}\protected@file@percent }
\newlabel{docs/more_layers:classifier-with-three-neuron-layers}{{5.5}{39}{Classifier with three neuron layers}{section.5.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.6}Exercises}{41}{section.5.6}\protected@file@percent }
\newlabel{docs/more_layers:exercises}{{5.6}{41}{Exercises}{section.5.6}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {6}Back propagation}{43}{chapter.6}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{docs/backprop:back-propagation}{{6}{43}{Back propagation}{chapter.6}{}}
\newlabel{docs/backprop::doc}{{6}{43}{Back propagation}{chapter.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6.1}Minimizing the error}{43}{section.6.1}\protected@file@percent }
\newlabel{docs/backprop:minimizing-the-error}{{6.1}{43}{Minimizing the error}{section.6.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6.2}Continuous activation function}{45}{section.6.2}\protected@file@percent }
\newlabel{docs/backprop:continuous-activation-function}{{6.2}{45}{Continuous activation function}{section.6.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6.3}Steepest descent}{49}{section.6.3}\protected@file@percent }
\newlabel{docs/backprop:steepest-descent}{{6.3}{49}{Steepest descent}{section.6.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6.4}Backprop algorithm}{51}{section.6.4}\protected@file@percent }
\newlabel{docs/backprop:backprop-algorithm}{{6.4}{51}{Backprop algorithm}{section.6.4}{}}
\newlabel{docs/backprop:bpa-lab}{{6.4}{51}{Backprop algorithm}{section.6.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.4.1}Code for backprop}{52}{subsection.6.4.1}\protected@file@percent }
\newlabel{docs/backprop:code-for-backprop}{{6.4.1}{52}{Code for backprop}{subsection.6.4.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6.5}Example with the circle}{53}{section.6.5}\protected@file@percent }
\newlabel{docs/backprop:example-with-the-circle}{{6.5}{53}{Example with the circle}{section.6.5}{}}
\newlabel{docs/backprop:circ-lab}{{6.5}{53}{Example with the circle}{section.6.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6.6}General remarks}{56}{section.6.6}\protected@file@percent }
\newlabel{docs/backprop:general-remarks}{{6.6}{56}{General remarks}{section.6.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6.7}Exercises}{56}{section.6.7}\protected@file@percent }
\newlabel{docs/backprop:exercises}{{6.7}{56}{Exercises}{section.6.7}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {7}Interpolation}{59}{chapter.7}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{docs/interpol:interpolation}{{7}{59}{Interpolation}{chapter.7}{}}
\newlabel{docs/interpol::doc}{{7}{59}{Interpolation}{chapter.7}{}}
\@writefile{toc}{\contentsline {section}{\numberline {7.1}Simulated data}{59}{section.7.1}\protected@file@percent }
\newlabel{docs/interpol:simulated-data}{{7.1}{59}{Simulated data}{section.7.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {7.2}ANNs for interpolation}{60}{section.7.2}\protected@file@percent }
\newlabel{docs/interpol:anns-for-interpolation}{{7.2}{60}{ANNs for interpolation}{section.7.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2.1}Backprop for one\sphinxhyphen {}dimensional functions}{62}{subsection.7.2.1}\protected@file@percent }
\newlabel{docs/interpol:backprop-for-one-dimensional-functions}{{7.2.1}{62}{Backprop for one\sphinxhyphen {}dimensional functions}{subsection.7.2.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {7.3}Exercises}{63}{section.7.3}\protected@file@percent }
\newlabel{docs/interpol:exercises}{{7.3}{63}{Exercises}{section.7.3}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {8}Rectification}{65}{chapter.8}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{docs/rectification:rectification}{{8}{65}{Rectification}{chapter.8}{}}
\newlabel{docs/rectification::doc}{{8}{65}{Rectification}{chapter.8}{}}
\@writefile{toc}{\contentsline {section}{\numberline {8.1}Interpolation with ReLU}{66}{section.8.1}\protected@file@percent }
\newlabel{docs/rectification:interpolation-with-relu}{{8.1}{66}{Interpolation with ReLU}{section.8.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {8.2}Classifiers with rectification}{67}{section.8.2}\protected@file@percent }
\newlabel{docs/rectification:classifiers-with-rectification}{{8.2}{67}{Classifiers with rectification}{section.8.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {8.3}Exercises}{68}{section.8.3}\protected@file@percent }
\newlabel{docs/rectification:exercises}{{8.3}{68}{Exercises}{section.8.3}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {9}Unsupervised learning}{69}{chapter.9}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{docs/unsupervised:unsupervised-learning}{{9}{69}{Unsupervised learning}{chapter.9}{}}
\newlabel{docs/unsupervised:un-lab}{{9}{69}{Unsupervised learning}{chapter.9}{}}
\newlabel{docs/unsupervised::doc}{{9}{69}{Unsupervised learning}{chapter.9}{}}
\@writefile{toc}{\contentsline {section}{\numberline {9.1}Clusters of points}{69}{section.9.1}\protected@file@percent }
\newlabel{docs/unsupervised:clusters-of-points}{{9.1}{69}{Clusters of points}{section.9.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {9.2}Voronoi areas}{71}{section.9.2}\protected@file@percent }
\newlabel{docs/unsupervised:voronoi-areas}{{9.2}{71}{Voronoi areas}{section.9.2}{}}
\newlabel{docs/unsupervised:vor-lab}{{9.2}{71}{Voronoi areas}{section.9.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {9.3}Naive clusterization}{72}{section.9.3}\protected@file@percent }
\newlabel{docs/unsupervised:naive-clusterization}{{9.3}{72}{Naive clusterization}{section.9.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9.1}{\ignorespaces Left: proper characteristic points. Right: one “dead body”.}}{75}{figure.9.1}\protected@file@percent }
\newlabel{docs/unsupervised:p-fig}{{9.1}{75}{Left: proper characteristic points. Right: one “dead body”}{figure.9.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9.2}{\ignorespaces From left to right: 5 characteristic points with one cluster split into two, with another cluster split into two, one dead body, and two dead bodies.}}{75}{figure.9.2}\protected@file@percent }
\newlabel{docs/unsupervised:id1}{{9.2}{75}{From left to right: 5 characteristic points with one cluster split into two, with another cluster split into two, one dead body, and two dead bodies}{figure.9.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {9.4}Clustering scale}{76}{section.9.4}\protected@file@percent }
\newlabel{docs/unsupervised:clustering-scale}{{9.4}{76}{Clustering scale}{section.9.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9.3}{\ignorespaces Dynamical clustering for various values of the scale \(d\).}}{77}{figure.9.3}\protected@file@percent }
\newlabel{docs/unsupervised:dyn-fig}{{9.3}{77}{Dynamical clustering for various values of the scale \(d\)}{figure.9.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.4.1}Interpretation via steepest descent}{78}{subsection.9.4.1}\protected@file@percent }
\newlabel{docs/unsupervised:interpretation-via-steepest-descent}{{9.4.1}{78}{Interpretation via steepest descent}{subsection.9.4.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {9.5}Interpretation via neural networks}{78}{section.9.5}\protected@file@percent }
\newlabel{docs/unsupervised:interpretation-via-neural-networks}{{9.5}{78}{Interpretation via neural networks}{section.9.5}{}}
\newlabel{docs/unsupervised:inn-sec}{{9.5}{78}{Interpretation via neural networks}{section.9.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.5.1}Representation with spherical coordinates}{79}{subsection.9.5.1}\protected@file@percent }
\newlabel{docs/unsupervised:representation-with-spherical-coordinates}{{9.5.1}{79}{Representation with spherical coordinates}{subsection.9.5.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.5.2}Scalar product maximization}{81}{subsection.9.5.2}\protected@file@percent }
\newlabel{docs/unsupervised:scalar-product-maximization}{{9.5.2}{81}{Scalar product maximization}{subsection.9.5.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {9.6}Exercises}{82}{section.9.6}\protected@file@percent }
\newlabel{docs/unsupervised:exercises}{{9.6}{82}{Exercises}{section.9.6}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {10}Self Organizing Maps}{83}{chapter.10}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{docs/som:self-organizing-maps}{{10}{83}{Self Organizing Maps}{chapter.10}{}}
\newlabel{docs/som::doc}{{10}{83}{Self Organizing Maps}{chapter.10}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10.1}{\ignorespaces Example of Kohonen’s networks. Left: 1\sphinxhyphen {}dim. grid of neurons \(N\) and 2\sphinxhyphen {}dim. input space \(D\). Right: 2\sphinxhyphen {}dim. grid of neurons \(N\) and 3\sphinxhyphen {}dim. input space \(D\). The red dot indicates the winner, and the gray oval marks its neighborhood.}}{83}{figure.10.1}\protected@file@percent }
\newlabel{docs/som:koh-fig}{{10.1}{83}{Example of Kohonen’s networks. Left: 1\sphinxhyphen {}dim. grid of neurons \(N\) and 2\sphinxhyphen {}dim. input space \(D\). Right: 2\sphinxhyphen {}dim. grid of neurons \(N\) and 3\sphinxhyphen {}dim. input space \(D\). The red dot indicates the winner, and the gray oval marks its neighborhood}{figure.10.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {10.1}Kohonen’s algorithm}{84}{section.10.1}\protected@file@percent }
\newlabel{docs/som:kohonen-s-algorithm}{{10.1}{84}{Kohonen’s algorithm}{section.10.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {10.1.1}2\sphinxhyphen {}dim. data and 1\sphinxhyphen {}dim. neuron grid}{84}{subsection.10.1.1}\protected@file@percent }
\newlabel{docs/som:dim-data-and-1-dim-neuron-grid}{{10.1.1}{84}{2\sphinxhyphen {}dim. data and 1\sphinxhyphen {}dim. neuron grid}{subsection.10.1.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10.2}{\ignorespaces Progress of Kohonen’s algorithm. The line, drawn to guide the eye, connects neurons with adjacent indices.}}{86}{figure.10.2}\protected@file@percent }
\newlabel{docs/som:kohstory-fig}{{10.2}{86}{Progress of Kohonen’s algorithm. The line, drawn to guide the eye, connects neurons with adjacent indices}{figure.10.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {10.1.2}2 dim. color map}{88}{subsection.10.1.2}\protected@file@percent }
\newlabel{docs/som:dim-color-map}{{10.1.2}{88}{2 dim. color map}{subsection.10.1.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {10.2}\(U\)\sphinxhyphen {}matrix}{90}{section.10.2}\protected@file@percent }
\newlabel{docs/som:u-matrix}{{10.2}{90}{\protect \(U\protect \)\sphinxhyphen {}matrix}{section.10.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10.3}{\ignorespaces Construction of \(U_{ij}\): a geometric average of the distances along the indicated links.}}{90}{figure.10.3}\protected@file@percent }
\newlabel{docs/som:udm-fig}{{10.3}{90}{Construction of \(U_{ij}\): a geometric average of the distances along the indicated links}{figure.10.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {10.2.1}Mapping colors on a line}{93}{subsection.10.2.1}\protected@file@percent }
\newlabel{docs/som:mapping-colors-on-a-line}{{10.2.1}{93}{Mapping colors on a line}{subsection.10.2.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {10.2.2}Wikipedia articles’ similarity}{94}{subsection.10.2.2}\protected@file@percent }
\newlabel{docs/som:wikipedia-articles-similarity}{{10.2.2}{94}{Wikipedia articles’ similarity}{subsection.10.2.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {10.3}Mapping 2\sphinxhyphen {}dim. data into a 2\sphinxhyphen {}dim. grid}{95}{section.10.3}\protected@file@percent }
\newlabel{docs/som:mapping-2-dim-data-into-a-2-dim-grid}{{10.3}{95}{Mapping 2\sphinxhyphen {}dim. data into a 2\sphinxhyphen {}dim. grid}{section.10.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10.4}{\ignorespaces Progress of Kohonen’s algorithm. The lines, drawn to guide the eye, connects neurons with adjacent indices.}}{96}{figure.10.4}\protected@file@percent }
\newlabel{docs/som:kohstory2-fig}{{10.4}{96}{Progress of Kohonen’s algorithm. The lines, drawn to guide the eye, connects neurons with adjacent indices}{figure.10.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {10.4}Topological properties}{97}{section.10.4}\protected@file@percent }
\newlabel{docs/som:topological-properties}{{10.4}{97}{Topological properties}{section.10.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {10.5}Lateral inhibition}{99}{section.10.5}\protected@file@percent }
\newlabel{docs/som:lateral-inhibition}{{10.5}{99}{Lateral inhibition}{section.10.5}{}}
\newlabel{docs/som:lat-lab}{{10.5}{99}{Lateral inhibition}{section.10.5}{}}
\newlabel{equation:docs/som:eq-lat}{{10.1}{99}{Lateral inhibition}{equation.10.5.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10.5}{\ignorespaces Network with inter\sphinxhyphen {}neuron couplings used for modeling lateral inhibition. All the neurons are connected to one another in both directions (lines without arrows).}}{100}{figure.10.5}\protected@file@percent }
\newlabel{docs/som:lat-fig}{{10.5}{100}{Network with inter\sphinxhyphen {}neuron couplings used for modeling lateral inhibition. All the neurons are connected to one another in both directions (lines without arrows)}{figure.10.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {10.6}Exercises}{101}{section.10.6}\protected@file@percent }
\newlabel{docs/som:exercises}{{10.6}{101}{Exercises}{section.10.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10.6}{\ignorespaces Image of pyramidal neurons (from \sphinxhref {http://brainmaps.org/index.php?p=screenshots}{brainmaps.org})}}{102}{figure.10.6}\protected@file@percent }
\newlabel{docs/som:pyr-fig}{{10.6}{102}{Image of pyramidal neurons (from \sphinxhref {http://brainmaps.org/index.php?p=screenshots}{brainmaps.org})}{figure.10.6}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {11}Concluding remarks}{103}{chapter.11}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{docs/conclusion:concluding-remarks}{{11}{103}{Concluding remarks}{chapter.11}{}}
\newlabel{docs/conclusion::doc}{{11}{103}{Concluding remarks}{chapter.11}{}}
\@writefile{toc}{\contentsline {section}{\numberline {11.1}Acknowledgments}{103}{section.11.1}\protected@file@percent }
\newlabel{docs/conclusion:acknowledgments}{{11.1}{103}{Acknowledgments}{section.11.1}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {12}Appendix}{105}{chapter.12}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{docs/appendix:appendix}{{12}{105}{Appendix}{chapter.12}{}}
\newlabel{docs/appendix::doc}{{12}{105}{Appendix}{chapter.12}{}}
\@writefile{toc}{\contentsline {section}{\numberline {12.1}How to run the book codes}{105}{section.12.1}\protected@file@percent }
\newlabel{docs/appendix:how-to-run-the-book-codes}{{12.1}{105}{How to run the book codes}{section.12.1}{}}
\newlabel{docs/appendix:app-run}{{12.1}{105}{How to run the book codes}{section.12.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {12.1.1}Locally}{105}{subsection.12.1.1}\protected@file@percent }
\newlabel{docs/appendix:locally}{{12.1.1}{105}{Locally}{subsection.12.1.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {12.2}\sphinxstylestrong {neural} package}{105}{section.12.2}\protected@file@percent }
\newlabel{docs/appendix:neural-package}{{12.2}{105}{\sphinxstylestrong {neural} package}{section.12.2}{}}
\newlabel{docs/appendix:app-lab}{{12.2}{105}{\sphinxstylestrong {neural} package}{section.12.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {12.2.1}\sphinxstylestrong {func.py} module}{106}{subsection.12.2.1}\protected@file@percent }
\newlabel{docs/appendix:func-py-module}{{12.2.1}{106}{\sphinxstylestrong {func.py} module}{subsection.12.2.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {12.2.2}\sphinxstylestrong {draw.py} module}{112}{subsection.12.2.2}\protected@file@percent }
\newlabel{docs/appendix:draw-py-module}{{12.2.2}{112}{\sphinxstylestrong {draw.py} module}{subsection.12.2.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {12.3}How to cite}{116}{section.12.3}\protected@file@percent }
\newlabel{docs/appendix:how-to-cite}{{12.3}{116}{How to cite}{section.12.3}{}}
\bibcite{docs/conclusion:id5}{Bar16}
\bibcite{docs/conclusion:id12}{BH69}
\bibcite{docs/conclusion:id8}{FR13}
\bibcite{docs/conclusion:id10}{Fre93}
\bibcite{docs/conclusion:id11}{FS91}
\bibcite{docs/conclusion:id3}{Gut16}
\bibcite{docs/conclusion:id14}{HR72}
\bibcite{docs/conclusion:id6}{KSJ+12}
\bibcite{docs/conclusion:id2}{Mat19}
\bibcite{docs/conclusion:id9}{MP43}
\bibcite{docs/conclusion:id7}{MullerRS12}
\bibcite{docs/conclusion:id13}{RIV91}
\@writefile{toc}{\contentsline {chapter}{Bibliography}{117}{chapter*.3}\protected@file@percent }
